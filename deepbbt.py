import os
import copy
import time
import math
import pickle
import random

import torch
import argparse
import numpy as np
import cma
from fastNLP import cache_results, Tester, DataSet
from transformers import (
    RobertaConfig,
    RobertaTokenizer,
    BertConfig,
    BertTokenizer,
    BartConfig,
    BartTokenizer,
    T5Config,
    T5Tokenizer,
    GPT2Config,
    GPT2Tokenizer,
)
from models.deep_modeling_roberta import RobertaForMaskedLM
from models.deep_modeling_bart import BartForConditionalGeneration
from models.deep_modeling_t5 import T5ForConditionalGeneration
from models.deep_modeling_gpt2 import GPT2LMHeadModel
from models.deep_modeling_bert import BertForMaskedLM
from models.deep_modeling_cpt import CPTForMaskedLM
from utils import hinge_loss
from sklearn.metrics import f1_score

import pickle
from scipy.optimize import minimize

parser = argparse.ArgumentParser()
parser.add_argument("--model_name", default='roberta-large',
                    # choices=['roberta-base', 'roberta-large',
                    #          'bert-base-uncased', 'bert-large-uncased',
                    #          'facebook/bart-base', 'facebook/bart-large',
                    #          't5-small', 't5-base', 't5-large', 't5-3b',
                    #          'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl',
                    #          ], 
                    type=str)
parser.add_argument("--model_path", default='roberta-large', type=str, help='The path of hugging face models for offline mode, default=model_name')
parser.add_argument("--task_name", default='SNLI', type=str)
parser.add_argument("--n_prompt_tokens", default=50, type=int)
parser.add_argument("--intrinsic_dim", default=500, type=int)
parser.add_argument("--k_shot", default=16, type=int)
parser.add_argument("--batch_size", default=32, type=int)
parser.add_argument("--budget", default=8000, type=int)
parser.add_argument("--popsize", default=20, type=int)
parser.add_argument("--bound", default=0, type=int)
parser.add_argument("--sigma1", default=1, type=float)
parser.add_argument("--sigma2", default=0.2, type=float)
parser.add_argument("--print_every", default=50, type=int)
parser.add_argument("--eval_every", default=100, type=int)
parser.add_argument("--device", default='cuda:3', type=str)
parser.add_argument("--alg", default='CMA', type=str)
parser.add_argument("--random_proj", default='normal', type=str)
parser.add_argument("--seed", default=42, type=int)
parser.add_argument("--loss_type", default='ce', type=str)
parser.add_argument(
    "--inference_framework",
    default='pt',
    type=str,
    help='''Which inference framework to use. 
         Currently supports `pt` and `ort`, standing for pytorch and Microsoft onnxruntime respectively'''
)
parser.add_argument(
    "--onnx_model_path",
    default=None,
    type=str,
    help='Path to your onnx model.'
)
parser.add_argument("--prefix", default='last_results', type=str, help="save data dir path prefix.")

# for Data Augmentation
parser.add_argument("--data_dir", default='datasets', type=str, help="'dataset' represents origin datasets, for DA, please select 'DA_datasets'. ")

# DFO

parser.add_argument("--budget2", default=0, type=int, help='two stage hyperparameter,0 refers not to use')
parser.add_argument("--replace_alg", default='Powell', type=str, choices=['CMA','openes','PEPG','DFO_tr','Nelder-Mead','Powell','SLSQP','COBYLA','L-BFGS-B'], help='select alg from CMA, openes, PEPG, DFO_tr, Nelder-Mead, Powell, SLSQP, COBYLA, BFGS etc')
parser.add_argument("--pop_mean", default=0, type=int, choices=[0,1], help='0:use result.xbest, 1:use result[5], CMA replace result[0] with mean solution to eval dev, presumably better with noise')


parser.add_argument("--instruction", default=False, action='store_true', help="")
parser.add_argument("--multiVerbalizer", default=False, action='store_true', help="multi Verbalizer for TREC.")
parser.add_argument("--use_tfidf", default=False, action='store_true', help="use tfidf to generate in-contexts.")
parser.add_argument("--sigma_setting", default='bbt2', type=str, help='[bbt2, lin, exp]')
parser.add_argument("--use_rlprompt", default=False, action='store_true', help="use hard prompt generated by rlprompt.")
# parser.add_argument("--dev_best", default=False, action='store_true', help="use dev best.")

args = parser.parse_args()

# below are free hyper-params
model_name = args.model_name
if model_name in ['t5-small', 't5-base', 't5-large', 't5-3b']:
    from dataloader_t5 import SST2Loader, AGNewsLoader, YelpPLoader, MRPCLoader, SNLILoader
    from metrics_t5 import SST2Metric, AGNewsMetric, YelpPMetric, MRPCMetric, SNLIMetric
elif model_name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']:
    from dataloader_gpt import SST2Loader, AGNewsLoader, YelpPLoader, MRPCLoader, SNLILoader
    from metrics_gpt import SST2Metric, AGNewsMetric, YelpPMetric, MRPCMetric, SNLIMetric
else:
    from dataloader import SST2Loader, AGNewsLoader, YelpPLoader, MRPCLoader, SNLILoader, TRECLoader
    from metrics import SST2Metric, AGNewsMetric, YelpPMetric, MRPCMetric, SNLIMetric, TRECMetric

model_path = args.model_path
task_name = args.task_name
n_prompt_tokens = args.n_prompt_tokens
intrinsic_dim = args.intrinsic_dim
k_shot = args.k_shot
batch_size = args.batch_size
budget = args.budget
bound = args.bound
sigma1 = args.sigma1
sigma2 = args.sigma2
if args.popsize > 0:
    popsize = args.popsize
else:
    popsize = 4 + 3 * np.log(intrinsic_dim)
device = args.device
alg = args.alg
random_proj = args.random_proj
seed = args.seed
loss_type = args.loss_type
print_every = args.print_every
eval_every = args.eval_every
# if task_name in ['mrpc', 'snli', 'qnli', 'rte']:
#     args.cat_or_add = 'cat'
inference_framework = args.inference_framework
onnx_model_path = args.onnx_model_path
save_hiddens = True
data_dir = args.data_dir
prefix = args.prefix

budget2 = args.budget2
replace_alg = args.replace_alg

print("###################################")
#for CMA
if alg == 'CMA':
    print("alg:", alg)

# for openes or PEPG
if alg != 'CMA':
    sigma_init = args.sigma_init
    learning_rate = args.learning_rate
    print("alg:", alg)
    print("sigma init, learning rate:", sigma_init, learning_rate)

pop_mean = args.pop_mean
# if pop_mean:
#     budget *= 1 + 1 / (eval_every//popsize - 1)
#     budget = int(budget)

print("pop_mean:", pop_mean)
print("budget:", budget)
print("budget2:", budget2)
print("###################################")

if task_name in ['SST-2', 'Yelp', 'MRPC']:
    num_labels = 2
elif task_name in ['SNLI']:
    num_labels = 3
elif task_name in ['AGNews']:
    num_labels = 4
elif task_name in ['TREC']:
    num_labels = 5
else:
    raise ValueError

args.bbt_version = 'deepbbt'

random.seed(seed)
np.random.seed(seed)
torch.manual_seed(seed)

class LMForwardAPI:
    def __init__(self, model_name='roberta-large', model_path='roberta-large', n_prompt_tokens=50, task_name='SST-2',
                 loss_type='hinge', args=None):
        self.args = args
        self.model_name = model_name
        self.model_path = model_path
        if model_name in ['roberta-base', 'roberta-large']:
            self.config = RobertaConfig.from_pretrained(model_path)
            self.tokenizer = RobertaTokenizer.from_pretrained(model_path)
            self.model = RobertaForMaskedLM.from_pretrained(
                model_path,
                config=self.config,
                n_prompt_tokens=n_prompt_tokens,
                inference_framework=inference_framework,
                onnx_model_path=onnx_model_path,
            )
            self.model.lm_head.bias = torch.nn.parameter.Parameter(torch.zeros(self.config.vocab_size))
        elif model_name in ['bert-base-uncased', 'bert-large-uncased']:
            self.config = BertConfig.from_pretrained(model_path)
            self.tokenizer = BertTokenizer.from_pretrained(model_path)
            self.model = BertForMaskedLM.from_pretrained(
                model_path,
                config=self.config,
                n_prompt_tokens=n_prompt_tokens,
            )
        elif model_name in ['facebook/bart-base', 'facebook/bart-large']:
            self.config = BartConfig.from_pretrained(model_path)
            self.tokenizer = BartTokenizer.from_pretrained(model_path)
            self.model = BartForConditionalGeneration.from_pretrained(
                model_path,
                config=self.config,
                n_prompt_tokens=n_prompt_tokens,
            )
        elif model_name in ['t5-small', 't5-base', 't5-large', 't5-3b']:
            self.config = T5Config.from_pretrained(model_path)
            self.tokenizer = T5Tokenizer.from_pretrained(model_path)
            self.model = T5ForConditionalGeneration.from_pretrained(
                model_path,
                config=self.config,
                n_prompt_tokens=n_prompt_tokens,
            )
        elif model_name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']:
            self.config = GPT2Config.from_pretrained(model_path)
            self.tokenizer = GPT2Tokenizer.from_pretrained(model_path)
            self.model = GPT2LMHeadModel.from_pretrained(
                model_path,
                config=self.config,
                n_prompt_tokens=n_prompt_tokens,
            )
        elif model_name in ['fnlp/cpt-large']:
            self.config = BartConfig.from_pretrained(model_path)
            self.tokenizer = BertTokenizer.from_pretrained(model_path)
            self.model = CPTForMaskedLM.from_pretrained(
                model_path,
                config=self.config,
                n_prompt_tokens=n_prompt_tokens,
            )
        else:
            raise NotImplementedError

        if random_proj == 'normal':
            self.config.output_hidden_states = True

        if inference_framework == 'ort':
            self.model.roberta = None
        self.best_prefix = torch.zeros(self.config.num_hidden_layers, n_prompt_tokens, self.config.hidden_size,
                                       device=device)
        self.best = None
        self.init_prompt = None
        self.model.to(device)
        self.model.eval()
        self.linear = torch.nn.ModuleList(
            [torch.nn.Linear(intrinsic_dim, n_prompt_tokens * self.config.hidden_size, bias=False) for _ in
             range(self.config.num_hidden_layers)])
        if random_proj == 'normal':
            # calculate std for normal distribution
            if model_name in ['roberta-base', 'roberta-large']:
                embedding = self.model.roberta.get_input_embeddings().weight.clone().cpu()
            elif model_name in ['bert-base-uncased', 'bert-large-uncased']:
                embedding = self.model.bert.get_input_embeddings().weight.clone().cpu()
            elif model_name in ['facebook/bart-base', 'facebook/bart-large', 'fnlp/cpt-large']:
                embedding = self.model.model.get_input_embeddings().weight.clone().cpu()
            elif model_name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']:
                embedding = self.model.transformer.get_input_embeddings().weight.clone().cpu()
            else:  # T5
                embedding = self.model.get_input_embeddings().weight.clone().cpu()
            mu_hat = np.mean(embedding.reshape(-1).detach().cpu().numpy())
            std_hat = np.std(embedding.reshape(-1).detach().cpu().numpy())
            mu = 0.0
            std = std_hat / (np.sqrt(intrinsic_dim) * args.sigma1)
            print('[Embedding] mu: {} | std: {} [RandProj]  mu: {} | std: {}'.format(mu_hat, std_hat, mu, std))
            for p in self.linear[0].parameters():
                torch.nn.init.normal_(p, 0.0, std)
            self.intermediate_stats = [(mu, std)]
        self.best_train_perf = 0.0
        self.best_dev_perf = 0.0
        self.num_call = 0
        self.print_every = print_every
        self.eval_every = eval_every
        self.loss_type = loss_type
        self.is_better_dev = self.config.num_hidden_layers * [0]
        if task_name == 'SST-2':
            self.metric = SST2Metric(args=args, target='labels', pred='logits', tokenizer=tokenizer)
            self.metric_key = 'acc'
            self.metric_name = 'SST2Metric'
        elif task_name == 'AGNews':
            self.metric = AGNewsMetric(args=args, target='labels', pred='logits', tokenizer=tokenizer)
            self.metric_key = 'acc'
            self.metric_name = 'AGNewsMetric'
        elif task_name == 'Yelp':
            self.metric = YelpPMetric(args=args, target='labels', pred='logits', tokenizer=tokenizer)
            self.metric_key = 'acc'
            self.metric_name = 'YelpPMetric'
        elif task_name == 'MRPC':
            self.metric = MRPCMetric(args=args, target='labels', pred='logits', tokenizer=tokenizer)
            self.metric_key = 'f1'
            self.metric_name = 'MRPCMetric'
        elif task_name == 'SNLI':
            self.metric = SNLIMetric(args=args, target='labels', pred='logits', tokenizer=tokenizer)
            self.metric_key = 'acc'
            self.metric_name = 'SNLIMetric'
        elif task_name == 'TREC':
            self.metric = TRECMetric(args=args, target='labels', pred='logits', tokenizer=tokenizer)
            self.metric_key = 'f1'
            self.metric_name = 'TRECMetric'
        else:
            raise NotImplementedError
        self.margin = self.metric.margin
        self.ce_loss = torch.nn.CrossEntropyLoss(reduction='mean')

    def calc_metric(self, logits, target):
        label_map = self.metric.label_map

        converted_target = target.clone()
        for key, val in label_map.items():
            converted_target[target == key] = val
        interest_index = list(label_map.keys())
        logits = logits[:, interest_index]
        pred = logits.argmax(dim=-1)

        if self.metric_key == 'acc':
            perf = (pred == converted_target).sum() / len(target)
        elif self.metric_key == 'f1':
            perf = f1_score(converted_target.detach().cpu().numpy().tolist(),
                            pred.detach().cpu().numpy().tolist(), average='macro')
        else:
            raise KeyError(f'[Metric] Only support [acc, f1], got {self.metric_key} instead.')

        if self.loss_type == 'hinge':
            loss = hinge_loss(logits, converted_target, margin=self.margin, reduction='sum').item() / len(target)
        elif self.loss_type == 'ce':
            loss = self.ce_loss(logits, converted_target).item()
        elif self.loss_type == 'perf':
            loss = -1 * perf
        else:
            raise KeyError(f'[Loss] Only support [hinge, ce, perf], got {self.loss_type} instead.')

        return loss, perf

    
    def calc_metric_for_multiVerbalizer(self, logits, target):
        if self.args.task_name == 'TREC':
            multi_interest_index = []
            multi_interest_index.append(self.tokenizer.encode("Definition")[1])
            multi_interest_index.append(self.tokenizer.encode("Description")[1])
            multi_interest_index.append(self.tokenizer.encode("Manner")[1])
            multi_interest_index.append(self.tokenizer.encode("Reason")[1])
            multi_interest_index.append(self.tokenizer.encode("Animal")[1])
            multi_interest_index.append(self.tokenizer.encode("Body")[1])
            multi_interest_index.append(self.tokenizer.encode("Color")[1])
            multi_interest_index.append(self.tokenizer.encode("Creative")[1])
            multi_interest_index.append(self.tokenizer.encode("Currency")[1])
            multi_interest_index.append(self.tokenizer.encode("Diseases")[1])
            multi_interest_index.append(self.tokenizer.encode("Medicine")[1])
            multi_interest_index.append(self.tokenizer.encode("Event")[1])
            multi_interest_index.append(self.tokenizer.encode("Food")[1])
            multi_interest_index.append(self.tokenizer.encode("Instrument")[1])
            multi_interest_index.append(self.tokenizer.encode("Lang")[1])
            multi_interest_index.append(self.tokenizer.encode("Letter")[1])
            multi_interest_index.append(self.tokenizer.encode("Entity")[1])
            multi_interest_index.append(self.tokenizer.encode("Plant")[1])
            multi_interest_index.append(self.tokenizer.encode("Product")[1])
            multi_interest_index.append(self.tokenizer.encode("Religion")[1])
            multi_interest_index.append(self.tokenizer.encode("Sport")[1])
            multi_interest_index.append(self.tokenizer.encode("Substance")[1])
            multi_interest_index.append(self.tokenizer.encode("Symbol")[1])
            multi_interest_index.append(self.tokenizer.encode("Technique")[1])
            multi_interest_index.append(self.tokenizer.encode("Term")[1])
            multi_interest_index.append(self.tokenizer.encode("Vehicle")[1])
            multi_interest_index.append(self.tokenizer.encode("Word")[1])
            multi_interest_index.append(self.tokenizer.encode("Abbreviation")[1])
            multi_interest_index.append(self.tokenizer.encode("Expression")[1])
            multi_interest_index.append(self.tokenizer.encode("Group")[1])
            multi_interest_index.append(self.tokenizer.encode("Organization")[1])
            multi_interest_index.append(self.tokenizer.encode("Individual")[1])
            multi_interest_index.append(self.tokenizer.encode("Title")[1])
            multi_interest_index.append(self.tokenizer.encode("Person")[1])
            multi_interest_index.append(self.tokenizer.encode("Human")[1])
            multi_interest_index.append(self.tokenizer.encode("Code")[1])
            multi_interest_index.append(self.tokenizer.encode("Count")[1])
            multi_interest_index.append(self.tokenizer.encode("Date")[1])
            multi_interest_index.append(self.tokenizer.encode("Distance")[1])
            multi_interest_index.append(self.tokenizer.encode("Money")[1])
            multi_interest_index.append(self.tokenizer.encode("Order")[1])
            multi_interest_index.append(self.tokenizer.encode("Number")[1])
            multi_interest_index.append(self.tokenizer.encode("Period")[1])
            multi_interest_index.append(self.tokenizer.encode("Percent")[1])
            multi_interest_index.append(self.tokenizer.encode("Speed")[1])
            multi_interest_index.append(self.tokenizer.encode("Temperature")[1])
            multi_interest_index.append(self.tokenizer.encode("Size")[1])
            multi_interest_index.append(self.tokenizer.encode("Weight")[1])
            multi_interest_index.append(self.tokenizer.encode("Area")[1])
            multi_interest_index.append(self.tokenizer.encode("Volume")[1])
            multi_interest_index.append(self.tokenizer.encode("City")[1])
            multi_interest_index.append(self.tokenizer.encode("Country")[1])
            multi_interest_index.append(self.tokenizer.encode("Mountain")[1])
            multi_interest_index.append(self.tokenizer.encode("Location")[1])
            multi_interest_index.append(self.tokenizer.encode("State")[1])

            multi_logits = logits[:, multi_interest_index]
            c0 = multi_logits[:, :4].mean(dim=1)
            c1 = multi_logits[:, 4:27].mean(dim=1)
            c2 = multi_logits[:, 27:29].mean(dim=1)
            c3 = multi_logits[:, 29:35].mean(dim=1)
            c4 = multi_logits[:, 35:50].mean(dim=1)
            c5 = multi_logits[:, 50:].mean(dim=1)
            logits = torch.stack([c0, c1, c2, c3, c4, c5]).T
        elif self.args.task_name == 'SNLI':
            multi_interest_index = []
            
            multi_interest_index.append(self.tokenizer.encode("Seriously")[1])
            multi_interest_index.append(self.tokenizer.encode("Finally")[1])
            multi_interest_index.append(self.tokenizer.encode("YES")[1])
            multi_interest_index.append(self.tokenizer.encode("Yeah")[1])
            multi_interest_index.append(self.tokenizer.encode("Exactly")[1])

            multi_interest_index.append(self.tokenizer.encode("Now")[1])
            multi_interest_index.append(self.tokenizer.encode("This")[1])
            multi_interest_index.append(self.tokenizer.encode("Likely")[1])
            multi_interest_index.append(self.tokenizer.encode("Apparently")[1])
            multi_interest_index.append(self.tokenizer.encode("Suddenly")[1])

            multi_interest_index.append(self.tokenizer.encode("Nah")[1])
            multi_interest_index.append(self.tokenizer.encode("Next")[1])
            multi_interest_index.append(self.tokenizer.encode("Alas")[1])
            multi_interest_index.append(self.tokenizer.encode("Nope")[1])
            multi_interest_index.append(self.tokenizer.encode("Later")[1])

            multi_logits = logits[:, multi_interest_index]
            c0 = multi_logits[:, :5].mean(dim=1)
            c1 = multi_logits[:, 5:10].mean(dim=1)
            c2 = multi_logits[:, 10:].mean(dim=1)
            logits = torch.stack([c0, c1, c2]).T
            # print('*******Use SNLI multi-verbalizers*********')
        elif self.args.task_name == 'AGNews':
            multi_interest_index = []
            
            multi_interest_index.append(self.tokenizer.encode("World")[1])
            multi_interest_index.append(self.tokenizer.encode("Iran")[1])
            multi_interest_index.append(self.tokenizer.encode("Iraq")[1])
            multi_interest_index.append(self.tokenizer.encode("Regional")[1])
            multi_interest_index.append(self.tokenizer.encode("BuzzFeed")[1])
            multi_interest_index.append(self.tokenizer.encode("PM")[1])

            multi_interest_index.append(self.tokenizer.encode("Sports")[1])
            multi_interest_index.append(self.tokenizer.encode("Athletics")[1])
            multi_interest_index.append(self.tokenizer.encode("Hockey")[1])
            multi_interest_index.append(self.tokenizer.encode("Sporting")[1])
            multi_interest_index.append(self.tokenizer.encode("Basketball")[1])
            multi_interest_index.append(self.tokenizer.encode("TEAM")[1])

            multi_interest_index.append(self.tokenizer.encode("Business")[1])
            multi_interest_index.append(self.tokenizer.encode("Investment")[1])
            multi_interest_index.append(self.tokenizer.encode("Trade")[1])
            multi_interest_index.append(self.tokenizer.encode("Industry")[1])
            multi_interest_index.append(self.tokenizer.encode("ET")[1])
            multi_interest_index.append(self.tokenizer.encode("business")[1])

            multi_interest_index.append(self.tokenizer.encode("Technology")[1])
            multi_interest_index.append(self.tokenizer.encode("tech")[1])
            multi_interest_index.append(self.tokenizer.encode("technology")[1])
            multi_interest_index.append(self.tokenizer.encode("Tech")[1])
            multi_interest_index.append(self.tokenizer.encode("Mobile")[1])
            multi_interest_index.append(self.tokenizer.encode("Wired")[1])

            multi_logits = logits[:, multi_interest_index]
            c0 = multi_logits[:, :6].mean(dim=1)
            c1 = multi_logits[:, 6:12].mean(dim=1)
            c2 = multi_logits[:, 12:18].mean(dim=1)
            c3 = multi_logits[:, 18:].mean(dim=1)
            logits = torch.stack([c0, c1, c2, c3]).T
            print('*******Use AGNews multi-verbalizers*********')
        elif self.args.task_name == 'MRPC':
            multi_interest_index = []
            
            multi_interest_index.append(self.tokenizer.encode("No")[1])
            multi_interest_index.append(self.tokenizer.encode("Still")[1])
            multi_interest_index.append(self.tokenizer.encode("meanwhile")[1])
            multi_interest_index.append(self.tokenizer.encode("Finally")[1])
            multi_interest_index.append(self.tokenizer.encode("Actually")[1])
            multi_interest_index.append(self.tokenizer.encode("Later")[1])

            multi_interest_index.append(self.tokenizer.encode("Yes")[1])
            multi_interest_index.append(self.tokenizer.encode("Furthermore")[1])
            multi_interest_index.append(self.tokenizer.encode("Thankfully")[1])
            multi_interest_index.append(self.tokenizer.encode("Instead")[1])
            multi_interest_index.append(self.tokenizer.encode("Rather")[1])
            multi_interest_index.append(self.tokenizer.encode("The")[1])

            multi_logits = logits[:, multi_interest_index]
            c0 = multi_logits[:, :6].mean(dim=1)
            c1 = multi_logits[:, 6:].mean(dim=1)
            logits = torch.stack([c0, c1]).T
            print('*******Use MRPC multi-verbalizers*********')
        else:
            NotImplementedError        

        label_map = self.metric.label_map

        converted_target = target.clone()
        for key, val in label_map.items():
            converted_target[target == key] = val
        # interest_index = list(label_map.keys())
        # logits = logits[:, interest_index]
        pred = logits.argmax(dim=-1)

        if self.metric_key == 'acc':
            perf = (pred == converted_target).sum() / len(target)
        elif self.metric_key == 'f1':
            perf = f1_score(converted_target.detach().cpu().numpy().tolist(),
                            pred.detach().cpu().numpy().tolist(), average='macro')
        else:
            raise KeyError(f'[Metric] Only support [acc, f1], got {self.metric_key} instead.')

        if self.loss_type == 'hinge':
            loss = hinge_loss(logits, converted_target, margin=self.margin, reduction='sum').item() / len(target)
        elif self.loss_type == 'ce':
            loss = self.ce_loss(logits, converted_target).item()
        elif self.loss_type == 'perf':
            loss = -1 * perf
        else:
            raise KeyError(f'[Loss] Only support [hinge, ce, perf], got {self.loss_type} instead.')

        return loss, perf

    
    def eval(self, prompt_embedding=None, layer_id=None, test_data=None):
        self.num_call += 1
        best_prefix = self.best_prefix.clone()
        if prompt_embedding is not None:
            prompt_embedding = torch.tensor(prompt_embedding).type(torch.float32)  # z
            prompt_embedding = self.linear[layer_id](prompt_embedding).reshape(-1, self.config.hidden_size)  # Az
            best_prefix[layer_id] = prompt_embedding

        self.model.set_prompt_embedding(best_prefix)

        for k, v in train_data.items():
            train_data[k] = v.to(device)
        with torch.no_grad():
            if model_name in ['t5-small', 't5-base', 't5-large', 't5-3b']:
                outputs = self.model(
                    input_ids=train_data['input_ids'],
                    attention_mask=train_data['attention_mask'],
                    decoder_input_ids=train_data['decoder_input_ids'],
                    decoder_attention_mask=train_data['decoder_attention_mask'],
                )
            elif model_name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']:
                outputs = self.model(
                    input_ids=train_data['input_ids'],
                    attention_mask=train_data['attention_mask'],
                )
            else:
                outputs = self.model(
                    input_ids=train_data['input_ids'],
                    attention_mask=train_data['attention_mask'],
                    mask_pos=train_data['mask_pos'],
                )
            logits = outputs['logits']
            if random_proj == 'normal' and len(self.intermediate_stats) == 1:
                # if is the first forward pass, record the range of hidden states of each layer
                print('Calculating std for random projections...')
                if self.model_name in ['facebook/bart-base', 'facebook/bart-large',
                                        't5-small', 't5-base', 't5-large', 't5-3b',
                                        'fnlp/cpt-large',
                                        ]:
                    hidden_states = outputs['encoder_hidden_states']
                else:
                    hidden_states = outputs['hidden_states']
                for i, h in enumerate(hidden_states[1:-1]):
                    if save_hiddens:
                        hid_path = './hidstates/{}'.format(self.model_name.split('/')[-1])
                        if not os.path.exists(hid_path):
                            os.makedirs(hid_path, exist_ok=True)
                        with open('{}/hidden_{}.bin'.format(hid_path, i + 1), 'wb') as f:
                            pickle.dump(h, f)
                    print('[Layer {}]'.format(i + 1))
                    hidden = h.clone().reshape(-1).detach().cpu().numpy()
                    mu_hat = np.mean(hidden)
                    std_hat = np.std(hidden)
                    max_h = np.max(hidden)
                    min_h = np.min(hidden)
                    print(' - Before clipping: mu=%.4f, std=%.4f, min=%.4f, max=%.4f' % (
                        mu_hat, std_hat, min_h, max_h))
                    # Clipping outliers
                    clip_round = 0
                    while clip_round < 5:
                        clip_round += 1
                        min_bound = mu_hat - 3 * std_hat
                        max_bound = mu_hat + 3 * std_hat
                        hidden = np.clip(hidden, min_bound, max_bound)
                        mu_hat = np.mean(hidden)
                        std_hat = np.std(hidden)
                        max_h = np.max(hidden)
                        min_h = np.min(hidden)
                        print(' - After clipping (round %d): mu=%.4f, std=%.4f, min=%.4f, max=%.4f' % (
                            clip_round, mu_hat, std_hat, min_h, max_h))
                    # Calculating std dev for the random projection
                    mu = 0.0
                    std = std_hat / (np.sqrt(intrinsic_dim) * args.sigma1)
                    print(' - Random Projection: mu=%.4f, std=%.4f' % (mu, std))
                    for p in self.linear[i + 1].parameters():
                        torch.nn.init.normal_(p, mu, std)
                    self.intermediate_stats.append((mu, std))
                assert len(self.intermediate_stats) == self.config.num_hidden_layers
                self.model.config.output_hidden_states = None
                print('Random projections initialized.')

            if args.multiVerbalizer:
                loss, perf = self.calc_metric_for_multiVerbalizer(logits, train_data['labels'])
            else:
                loss, perf = self.calc_metric(logits, train_data['labels'])

            if perf > self.best_train_perf:
                self.best_train_perf = perf

            if self.num_call % self.print_every == 0:
                print(
                    '[# API Calls {}] loss: {}. Current perf: {}. Best perf so far: {}'.format(
                        self.num_call,
                        round(float(loss), 4),
                        round(float(perf), 4),
                        round(float(self.best_train_perf), 4)))

            if self.num_call % self.eval_every == 0:
                print('********* Evaluated on dev set *********')
                for k, v in dev_data.items():
                    dev_data[k] = v.to(device)
                with torch.no_grad():
                    if model_name in ['t5-small', 't5-base', 't5-large', 't5-3b']:
                        logits = self.model(
                            input_ids=dev_data['input_ids'],
                            attention_mask=dev_data['attention_mask'],
                            decoder_input_ids=dev_data['decoder_input_ids'],
                            decoder_attention_mask=dev_data['decoder_attention_mask'],
                        )['logits']
                    elif model_name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']:
                        logits = self.model(
                            input_ids=dev_data['input_ids'],
                            attention_mask=dev_data['attention_mask'],
                        )['logits']
                    else:
                        logits = self.model(
                            input_ids=dev_data['input_ids'],
                            attention_mask=dev_data['attention_mask'],
                            mask_pos=dev_data['mask_pos'],
                        )['logits']

                dev_loss, dev_perf = self.calc_metric(logits, dev_data['labels'])
                if dev_perf > self.best_dev_perf:
                    self.is_better_dev[layer_id] = 1
                    self.best_dev_perf = dev_perf
                    self.best = best_prefix.clone()#torch.Size([24, 50, 1024])
                    print("###self.num_call:",self.num_call)
                    # print("###dev_perf > self.best_dev_perf,dev_perf ,self.best_dev_perf:",dev_perf ,self.best_dev_perf)

                print('Dev loss: {}. Dev perf: {}. Best dev perf: {}'.format(
                    round(float(dev_loss), 4),
                    round(float(dev_perf), 4),
                    round(float(self.best_dev_perf), 4)))
                print('********* Done *********')
            return loss

    def refresh_is_better_dev(self, layer_id = None):
        self.is_better_dev[layer_id] = 0
        return self.is_better_dev[layer_id]


if model_name in ['roberta-base', 'roberta-large']:
    tokenizer = RobertaTokenizer.from_pretrained(model_path)
elif model_name in ['bert-base-uncased', 'bert-large-uncased', 'fnlp/cpt-large']:
    tokenizer = BertTokenizer.from_pretrained(model_path)
elif model_name in ['facebook/bart-base', 'facebook/bart-large']:
    tokenizer = BartTokenizer.from_pretrained(model_path)
elif model_name in ['t5-small', 't5-base', 't5-large', 't5-3b']:
    tokenizer = T5Tokenizer.from_pretrained(model_path)
elif model_name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']:
    tokenizer = GPT2Tokenizer.from_pretrained(model_path)
else:
    raise NotImplementedError

cache_fn = f"caches/data_{model_name.replace('/', '-')}_{data_dir}_{task_name}_{n_prompt_tokens}_{seed}.pt"

DataLoader = {
    'SST-2': SST2Loader,
    'AGNews': AGNewsLoader,
    'Yelp': YelpPLoader,
    'MRPC': MRPCLoader,
    'SNLI': SNLILoader,
    'TREC': TRECLoader,
}


@cache_results(cache_fn, _refresh=True)
def get_data(task_name, tokenizer):
    splits = ['train', 'dev']
    data_bundle = DataLoader[task_name](tokenizer=tokenizer, n_prompt_tokens=n_prompt_tokens, data_dir=data_dir, args=args).my_load(splits, seed)
    return data_bundle

data_bundle = get_data(task_name=task_name, tokenizer=tokenizer)
train_data, dev_data = data_bundle.get_dataset('train'), data_bundle.get_dataset('dev')

for ds in [train_data, dev_data]:
    ds.set_pad_val('input_ids', tokenizer.pad_token_id if tokenizer.pad_token_id is not None else 0)
    ds.set_pad_val('attention_mask', 0)

print('# of train data: {}'.format(len(train_data)))
print('Example:')
print(train_data[0])
print('\n# of dev data: {}'.format(len(dev_data)))
print('Example:')
print(dev_data[0])

if model_name in ['t5-small', 't5-base', 't5-large', 't5-3b']:
    train_data = {
        'input_ids': torch.tensor(train_data['input_ids'].get(list(range(len(train_data))))),
        'attention_mask': torch.tensor(train_data['attention_mask'].get(list(range(len(train_data))))),
        'decoder_input_ids': torch.tensor(train_data['decoder_input_ids'].get(list(range(len(train_data))))),
        'decoder_attention_mask': torch.tensor(train_data['decoder_attention_mask'].get(list(range(len(train_data))))),
        'labels': torch.tensor(train_data['labels'].get(list(range(len(train_data))))),
    }
    dev_data = {
        'input_ids': torch.tensor(dev_data['input_ids'].get(list(range(len(dev_data))))),
        'attention_mask': torch.tensor(dev_data['attention_mask'].get(list(range(len(dev_data))))),
        'decoder_input_ids': torch.tensor(dev_data['decoder_input_ids'].get(list(range(len(dev_data))))),
        'decoder_attention_mask': torch.tensor(dev_data['decoder_attention_mask'].get(list(range(len(dev_data))))),
        'labels': torch.tensor(dev_data['labels'].get(list(range(len(dev_data))))),
    }
elif model_name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']:
    train_data = {
        'input_ids': torch.tensor(train_data['input_ids'].get(list(range(len(train_data))))),
        'attention_mask': torch.tensor(train_data['attention_mask'].get(list(range(len(train_data))))),
        'labels': torch.tensor(train_data['labels'].get(list(range(len(train_data))))),
    }
    dev_data = {
        'input_ids': torch.tensor(dev_data['input_ids'].get(list(range(len(dev_data))))),
        'attention_mask': torch.tensor(dev_data['attention_mask'].get(list(range(len(dev_data))))),
        'labels': torch.tensor(dev_data['labels'].get(list(range(len(dev_data))))),
    }
else:
    train_data = {
        'input_ids': torch.tensor(train_data['input_ids'].get(list(range(len(train_data))))),
        'attention_mask': torch.tensor(train_data['attention_mask'].get(list(range(len(train_data))))),
        'mask_pos': torch.tensor(train_data['mask_pos'].get(list(range(len(train_data))))),
        'labels': torch.tensor(train_data['labels'].get(list(range(len(train_data))))),
    }
    dev_data = {
        'input_ids': torch.tensor(dev_data['input_ids'].get(list(range(len(dev_data))))),
        'attention_mask': torch.tensor(dev_data['attention_mask'].get(list(range(len(dev_data))))),
        'mask_pos': torch.tensor(dev_data['mask_pos'].get(list(range(len(dev_data))))),
        'labels': torch.tensor(dev_data['labels'].get(list(range(len(dev_data))))),
    }

model_forward_api = LMForwardAPI(
    model_name=model_name,
    model_path=model_path,
    n_prompt_tokens=n_prompt_tokens,
    task_name=task_name,
    loss_type=loss_type,
    args=args,
)

cma_opts = {
    'seed': seed,
    'popsize': popsize,
    'maxiter': budget // (popsize * model_forward_api.config.num_hidden_layers),
    'verbose': -1,
}
if bound > 0:
    cma_opts['bounds'] = [-1 * bound, 1 * bound]

if args.sigma_setting == 'bbt2':
    sigmas = [sigma1]
    for i in range(model_forward_api.config.num_hidden_layers - 1):
        sigmas.append(sigma2)
elif args.sigma_setting == 'lin':
    sigmas = [sigma1]
    diff = (sigma1 - sigma2) / (model_forward_api.config.num_hidden_layers - 1)
    for i in range(1, model_forward_api.config.num_hidden_layers):
        sigmas.append(sigma1 - diff * i)
elif args.sigma_setting == 'exp':
    sigmas = [sigma1]
    diff = sigma1 - sigma2
    for i in range(1, model_forward_api.config.num_hidden_layers):
        sigmas.append(np.exp(-i/5) * diff + sigma2)
assert len(sigmas) == model_forward_api.config.num_hidden_layers
es_list = [
    cma.CMAEvolutionStrategy(intrinsic_dim * [0], sigmas[i], inopts=cma_opts)
    for i in range(model_forward_api.config.num_hidden_layers)
]

if budget2 == 0:
    start_time = time.time()

    for _ in range(budget // (int(popsize) * model_forward_api.config.num_hidden_layers)):
        for i, es in enumerate(es_list):
            solutions = es.ask()
            fitnesses = [model_forward_api.eval(x, i) for x in solutions]
            es.tell(solutions, fitnesses)
            model_forward_api.best_prefix[i] = model_forward_api.linear[i](
                torch.tensor(es.result.xbest).type(torch.float32)).reshape(-1,
                                                                        model_forward_api.config.hidden_size)  # set best cv
        if _  % 2 == 0:
            epoch_num = _ * (int(popsize) * model_forward_api.config.num_hidden_layers)
            if not os.path.exists(f'./{prefix}/{epoch_num}_results/{task_name}/{seed}'):
                os.makedirs(f'./{prefix}/{epoch_num}_results/{task_name}/{seed}')
            torch.save(model_forward_api.best_prefix, f=f'./{prefix}/{epoch_num}_results/{task_name}/{seed}/best.pt')


    end_time = time.time()
    print('Done. Elapsed time: {} (mins)'.format((end_time - start_time) / 60))
    if not os.path.exists(f'./{prefix}/last_epoch_results/{task_name}/{seed}'):
        os.makedirs(f'./{prefix}/last_epoch_results/{task_name}/{seed}')

    if not os.path.exists(f'./{prefix}/dev_best_results/{task_name}/{seed}'):
        os.makedirs(f'./{prefix}/dev_best_results/{task_name}/{seed}')

    torch.save(model_forward_api.best, f=f'./{prefix}/dev_best_results/{task_name}/{seed}/best.pt')
    torch.save(model_forward_api.best_prefix, f=f'./{prefix}/last_epoch_results/{task_name}/{seed}/best.pt')

else:
    start_time = time.time()

    # es.optimize(model_forward_api.eval)
    # #this func executes the same way the loop below, and calls lots time of eval api
    result = model_forward_api.config.num_hidden_layers * [0]
    best_result = model_forward_api.config.num_hidden_layers * [0]
    for round_ in range(budget // (int(popsize) * model_forward_api.config.num_hidden_layers)):
        for i, es in enumerate(es_list):# i refers to layer_num, 0->24 0>24 ...
            print("layer i:",i)
            solutions = es.ask()
            #ask delivers new candidate solutions and tell updates the optim instance by passing the respective function values
            fitnesses = [model_forward_api.eval(x, i) for x in solutions]
            #every time we call eval (per 20 popsize), print loss
            #serial模式，20个种群都输入fitnesses
            es.tell(solutions, fitnesses)
            result[i] = es.result#[0]:solution [1]:best f value [2]
            # print("i,result[i][1]:",i,result[i][1])
            # print("fitness_list[0]:",fitnesses[0])
            # model_forward_api.best_prefix[i] = model_forward_api.linear[i](torch.tensor(result[i].xbest).type(torch.float32)).reshape(-1,model_forward_api.config.hidden_size)  # set best cv
            #ndarray(500,1) to torch.Size([51200]) to torch.Size([50, 1024])
            
            if round_ == 0:
                best_result[i] = result[i][5] if pop_mean else result[i][0]
                model_forward_api.best_prefix[i] = model_forward_api.linear[i](torch.tensor(best_result[i]).type(torch.float32)).reshape(-1,model_forward_api.config.hidden_size)  # set best cv
                model_forward_api.refresh_is_better_dev(i)
            else:
                if model_forward_api.is_better_dev[i]:
                    print("###is_better_dev")
                    best_result[i] = result[i][5] if pop_mean else result[i][0]
                    model_forward_api.best_prefix[i] = model_forward_api.linear[i](torch.tensor(best_result[i]).type(torch.float32)).reshape(-1,model_forward_api.config.hidden_size)  # set best cv
                    model_forward_api.refresh_is_better_dev(i)
    #         if i==len(es_list)-1:
    #             es.logger.add()  # write data to disc to be plotted
    #             es.disp()
    # es_list[-1].logger.plot()
    # savefig("./cmaplot.png")

    print("finish CMA. start 2nd stage DFO")
    for i in range(model_forward_api.config.num_hidden_layers):# i refers to layer_num #0->..->0,...,24-->..->24
        print("layer i:",i)
        max_iter=budget2 // model_forward_api.config.num_hidden_layers
        def short_api(x_):#[500,1] to [20]
            fitness = model_forward_api.eval(x_,i)
            return fitness

        options={}
        for methods in ['Powell','Nelder-Mead']:#, "maxfev": 100 powell do not need seed
            options[methods]={"disp": True, "maxfev":max_iter}
        for methods in ['BFGS','SLSQP','L-BFGS-B']:#, "maxiter": 80/200
            options[methods]={"disp": True, "maxiter":max_iter}
        for methods in ['COBYLA']:
            options[methods]={"disp": True,"maxiter":max_iter}
        options['Powell'].update({"ftol": 1e-26}) 
        options['Nelder-Mead'].update({"ftol": 1e-26})
        options['COBYLA'].update({"tol": 1e-25})
        options['BFGS'].update({"gtol": 1e-5})
        options['SLSQP'].update({"ftol": 1e-26})

        start_time = time.time()
        res = minimize(short_api,  best_result[i],  method=replace_alg, options=options[replace_alg])
        if model_forward_api.is_better_dev[i]:
            print("###is_better_dev")
            model_forward_api.best_prefix[i] = model_forward_api.linear[i](torch.tensor(res.x).type(torch.float32)).reshape(-1,model_forward_api.config.hidden_size)  # set best cv
            model_forward_api.refresh_is_better_dev(i)
        print("layer,loss(fitnesses):",i,res.fun)


    end_time = time.time()
    print('Done. Elapsed time: {} (mins)'.format((end_time - start_time) / 60))
    if not os.path.exists(f'./results/{task_name}/{seed}'):
        os.makedirs(f'./results/{task_name}/{seed}')

    torch.save(model_forward_api.best, f=f'./dev_best_results/{task_name}/{seed}/best.pt')
    torch.save(model_forward_api.best_prefix, f=f'./last_epoch_results/{task_name}/{seed}/best.pt')
